{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "947473b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "case_land = pd.read_parquet(r\"C:\\Users\\es422\\Documents\\xentity\\BLM\\MLRS\\Data\\Snapshots\\NLSDB\\2025_03-03_NLSDB.gdb\\CaseLands_03032025_1330.parquet\")\n",
    "case_land = case_land.drop(columns='Shape')\n",
    "case_land.to_parquet(\"CaseLands_03032025_1330.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e9d953d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: schemas/account_rpt_schema.json\n",
      "Saved: schemas/action_schema.json\n",
      "Saved: schemas/admin_unit_schema.json\n",
      "Saved: schemas/admin_unit_agg_schema.json\n",
      "Saved: schemas/blm_case_schema.json\n",
      "Saved: schemas/blm_product_schema.json\n",
      "Saved: schemas/case_action_schema.json\n",
      "Saved: schemas/case_customer_schema.json\n",
      "Saved: schemas/case_land_schema.json\n",
      "Saved: schemas/case_transaction_schema.json\n",
      "Saved: schemas/intrel_d_schema.json\n",
      "Saved: schemas/product_fee_schema.json\n",
      "Saved: schemas/rpt_calendar_schema.json\n",
      "Saved: schemas/case_action_status_d_schema.json\n",
      "Saved: schemas/commodity_d_schema.json\n",
      "Saved: schemas/case_group_d_schema.json\n",
      "Saved: schemas/meridian_d_schema.json\n",
      "Saved: schemas/survey_type_d_schema.json\n",
      "Saved: schemas/action_case_schema.json\n",
      "Saved: schemas/action_land_schema.json\n",
      "Saved: schemas/case_admin_unit_schema.json\n",
      "Saved: schemas/record_type_schema.json\n",
      "Saved: schemas/supplemental_use_schema.json\n",
      "Saved: schemas/us_right_case_land_schema.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "schema_xcel = r\"C:\\Users\\es422\\Documents\\xentity\\BLM\\MLRS\\Data\\Snapshots\\MLRS\\MLRS_Pub_Extract_Schema_20241104.xlsx\"\n",
    "df = pd.read_excel(schema_xcel, sheet_name='Tables', header = None)\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(\"schemas\", exist_ok=True)\n",
    "\n",
    "# Initialize\n",
    "tables = {}\n",
    "current_table = None\n",
    "\n",
    "# Loop through spreadsheet rows\n",
    "for _, row in df.iterrows():\n",
    "    table_candidate = row[0]\n",
    "    column_type = row[1] if len(row) > 1 else None\n",
    "\n",
    "    # If only table name is present (new section)\n",
    "    if pd.notna(table_candidate) and pd.isna(column_type):\n",
    "        current_table = table_candidate.strip()\n",
    "        tables[current_table] = []\n",
    "    elif current_table and pd.notna(table_candidate) and pd.notna(column_type):\n",
    "        column_name = table_candidate.strip()\n",
    "        tables[current_table].append({\n",
    "            \"name\": column_name,\n",
    "            \"type\": \"STRING\"\n",
    "        })\n",
    "\n",
    "# Write each schema as JSON file\n",
    "for table, schema in tables.items():\n",
    "    filename = f\"schemas/{table.lower()}_schema.json\"\n",
    "    with open(filename, \"w\") as f:\n",
    "        json.dump(schema, f, indent=4)\n",
    "    print(f\"Saved: {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2096ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ File saved: load_commands.txt\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "schema_xcel = r\"C:\\Users\\es422\\Documents\\xentity\\BLM\\MLRS\\Data\\Snapshots\\MLRS\\MLRS_Pub_Extract_Schema_20241104.xlsx\"\n",
    "df = pd.read_excel(schema_xcel, sheet_name='Tables', header = None)\n",
    "\n",
    "# Snapshot date\n",
    "snapshot_date = \"20250401\"\n",
    "\n",
    "# GCS and BQ setup\n",
    "gcs_base = f\"gs://sandbox-blm-seta-dqimp-qaqc/snapshots/{snapshot_date}\"\n",
    "bq_dataset = \"blm_dqimp_qaqc\"\n",
    "\n",
    "# Extract table names\n",
    "tables = []\n",
    "for _, row in df.iterrows():\n",
    "    table_candidate = row[0]\n",
    "    column_type = row[1] if len(row) > 1 else None\n",
    "    if pd.notna(table_candidate) and pd.isna(column_type):\n",
    "        tables.append(table_candidate.strip())\n",
    "\n",
    "# Create the output lines\n",
    "lines = []\n",
    "for table in tables:\n",
    "    upper_table = table.upper()\n",
    "    lower_table = table.lower()\n",
    "\n",
    "    lines.append(f\"combine {upper_table}:\")\n",
    "    lines.append(\n",
    "        f\"gsutil compose {gcs_base}/MC_{upper_table}.csv {gcs_base}/CR_FULL_{upper_table}.csv {gcs_base}/{upper_table}.csv\"\n",
    "    )\n",
    "    lines.append(\n",
    "        f\"gsutil rm {gcs_base}/MC_{upper_table}.csv {gcs_base}/CR_FULL_{upper_table}.csv\\n\"\n",
    "    )\n",
    "    lines.append(f\"Load {upper_table}:\")\n",
    "    lines.append(\n",
    "        f\"bq load --source_format=CSV --field_delimiter=\\\"|\\\" --skip_leading_rows=0 --schema={lower_table}_schema.json {bq_dataset}.{lower_table}_{snapshot_date} {gcs_base}/{upper_table}.csv\\n\"\n",
    "    )\n",
    "\n",
    "# Save to file\n",
    "with open(\"load_commands.txt\", \"w\") as f:\n",
    "    f.write(\"\\n\".join(lines))\n",
    "\n",
    "print(\"✅ File saved: load_commands.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d63c1d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
